### Background
Human activity recognition plays a key role in the development of life-assistance methods. For example, a disability assistance device designed to alert others when the patient is in a medical crisis needs to be trained to recognize certain human postures that indicate that the patient wearing the device is in need of immediate assistance. Robots designed to perform human tasks need to be trained to walk, sit, lift, and push like humans. The development of such devices is built upon the foundations of highly trained machine learning models using complex human activity datasets.

In Palumbo, Filippo et al (2016), a related research study was done on human subjects where multiple sensors were worn by the human subjects for a period of time. The was introduced by the paper as Multisensor data fusion (AReM), and is capable of detecting the Received Signal Strength (RSS) between the sensors when an activity or an action is performed by the subject. 

The study measured 7 types of activities: standing, walking, sitting, lying, cycling, and two types of bendings, and collected time series data based on the signal strength the sensors transmitted when the activity was performed. To elaborate on the meaning of this dataset, it’s worth noting that there are three sensors worn by each research subject as shown in the left picture below. The study collected two types of values, mean and variance, of the number of readings between each pair of sensors at a certain time: ‘rss12’ indicates the measures between sensors 1 and 2, ‘rss13’ indicates the measures between sensors 1 and 3, and ‘rss23’ indicates the measures between sensors 2 and 3. The study also measured two types of bendings, shown as ‘bending1’ and ‘bending2’ in the right picture below.

![Figure 1](https://i.imgur.com/3Ewaftx.png) ![Figure 2](https://i.imgur.com/IpFsbFg.png)

### Repo Directory
AReM - raw input dataset retrieved from study
input_data_prep.ipynb - script to wrangle and reformat data
rss_dashboard.py - script to launch the dashboard for visualizations
activity_variance.csv - processed data for measure 'variance', part of input data for dashboard and rest of project
activity_mean.csv - processed data for measure 'mean', part of input data for dashboard and rest of project

### Project Goal
The goal of this project is to utilize the signal strength data gathered from the aforementioned study to explore machine learning use cases on human activity recognitions that can be implemented programmatically. The planned use cases are listed below:

1. Applying dimensionality reductions (PCA) on the dataset. The data has a large number of dimensions, and an important step while analyzing this data is to perform PCA to determine the interrelations between variables, detect abnormalities, reduce noise in data, and evaluate the significance of each attribute. This can be achieved by building a custom class in python scripts that has the functionalities of normalizing the dataset and mathematical algorithms such as eigencompositions, and applying the class on the dataset to interpret the results.
2. One of the most substantial parts of the study done by Filippo et al (2016) is to build a machine learning model that was trained on existing signal strength data, and hence upon receiving a new dataset, the model is capable of recognizing which activity the dataset represents without human investigations. The use of classification algorithms, such as K-means clustering, Random Forest, Decision Tree algorithm, and Neural Networks, can be used to achieve this objective. Most likely, a model will be built for each of the classification algorithms, and trained on the dataset to determine which algorithm is the most suitable for this use case based on the performance.
3. As the data retrieved from the repository was in time series, it could be substantial to visualize whether there are seasonalities within each activity. As mentioned in the data description, the study paired up the sensors worn by the research subjects and collected the mean and variance data for the number of readings on each pair of sensors at a particular time. Therefore, another use case could be to calculate the total signal strength for all observed instances as the target variable, and the original variables as predictive variables, then apply regression algorithms such as Linear Regression and Logistic Regression to perform forecasting tasks on the data. Once the regression model has been trained and is able to accurately predict the total signal strengths over time, the individual RSS between sensors could also be calculated individually based on the value of ‘(each RSS column / the total signal strength) * each RSS column’. The result of this can be visualized using graphing libraries such as seaborn to determine whether the signal strength has patterns in terms of time series.
